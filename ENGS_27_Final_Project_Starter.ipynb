{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0AjyVnUm_oz"
   },
   "source": [
    "# ENGS 27 Final Project Starter Code\n",
    "[Enter Names of Group Members Here]\n",
    "\n",
    "Please copy this code to work on your own version!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPl2fJZZnK25"
   },
   "source": [
    "The following code interfaces with the noisy channel, hosted on a Dartmouth website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:57:51.921807Z",
     "start_time": "2025-08-28T20:57:51.918842Z"
    },
    "id": "ZrMhDgAQnIEo"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import subprocess\n",
    "\n",
    "def noisy_channel(bits: str) -> str:\n",
    "    \"\"\"\n",
    "    Calls curl to POST the given bits to the test.py endpoint\n",
    "    and returns the stdout response as a string.\n",
    "    \"\"\"\n",
    "    # Build the curl command and arguments:\n",
    "    cmd = [\n",
    "        \"curl\",\n",
    "        \"-X\", \"POST\",\n",
    "        \"-d\", f\"bits={bits}\",\n",
    "        \"https://engs27.host.dartmouth.edu/cgi-bin/noisychannel.py\"\n",
    "    ]\n",
    "\n",
    "    # Run the command, capture stdout/stderr\n",
    "    result = subprocess.run(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,       # return strings instead of bytes\n",
    "        check=False      # we’ll inspect returncode manually\n",
    "    )\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        # curl failed. You can raise, log, or return stderr.\n",
    "        raise RuntimeError(f\"curl failed (code {result.returncode}):\\n{result.stderr}\")\n",
    "\n",
    "    return result.stdout.split(\"<body>\")[1].split(\"</body>\")[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtUhazgjpWp2"
   },
   "source": [
    "Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:28:21.736021Z",
     "start_time": "2025-08-28T20:28:20.473362Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1755223470912,
     "user": {
      "displayName": "Josh Meise",
      "userId": "02876248466956909039"
     },
     "user_tz": 240
    },
    "id": "ok9Ic7z3pVvm",
    "outputId": "d0aece1e-ae0b-47f0-aeb5-22a2c08c99ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0110'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_channel(\"0110\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's collect data from different string lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:57:53.254917Z",
     "start_time": "2025-08-28T20:57:52.546245Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:34:01.602875Z",
     "start_time": "2025-08-28T20:29:24.319864Z"
    },
    "id": "oq1ZjizXpdbE"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m     onezero_trials\u001b[38;5;241m.\u001b[39mappend(noisy_channel(onezero))\n\u001b[1;32m     23\u001b[0m     zeroone_trials\u001b[38;5;241m.\u001b[39mappend(noisy_channel(zeroone))\n\u001b[0;32m---> 24\u001b[0m     zerozero_trials\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnoisy_channel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzerozero\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m results_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone_trials\u001b[39m\u001b[38;5;124m'\u001b[39m: one_trials,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero_trials\u001b[39m\u001b[38;5;124m'\u001b[39m: zero_trials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzerozero_trials\u001b[39m\u001b[38;5;124m'\u001b[39m: zerozero_trials\n\u001b[1;32m     33\u001b[0m }\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoisy_channel_results.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36mnoisy_channel\u001b[0;34m(bits)\u001b[0m\n\u001b[1;32m     10\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-X\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbits=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://engs27.host.dartmouth.edu/cgi-bin/noisychannel.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m ]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Run the command, capture stdout/stderr\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# return strings instead of bytes\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# we’ll inspect returncode manually\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# curl failed. You can raise, log, or return stderr.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurl failed (code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mreturncode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/subprocess.py:2021\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2015\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2016\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2019\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2021\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "one = '1'\n",
    "zero = '0'\n",
    "\n",
    "oneone = '11'\n",
    "onezero = '10'\n",
    "zeroone = '01'\n",
    "zerozero = '00'\n",
    "\n",
    "num_trials = 100\n",
    "\n",
    "one_trials: list[str] = []\n",
    "zero_trials: list[str] = []\n",
    "oneone_trials: list[str] = []\n",
    "onezero_trials: list[str] = []\n",
    "zeroone_trials: list[str] = []\n",
    "zerozero_trials: list[str] = []\n",
    "\n",
    "for _ in range(num_trials):\n",
    "    one_trials.append(noisy_channel(one))\n",
    "    zero_trials.append(noisy_channel(zero))\n",
    "    oneone_trials.append(noisy_channel(oneone))\n",
    "    onezero_trials.append(noisy_channel(onezero))\n",
    "    zeroone_trials.append(noisy_channel(zeroone))\n",
    "    zerozero_trials.append(noisy_channel(zerozero))\n",
    "\n",
    "results_data = {\n",
    "    'one_trials': one_trials,\n",
    "    'zero_trials': zero_trials,\n",
    "    'oneone_trials': oneone_trials,\n",
    "    'onezero_trials': onezero_trials,\n",
    "    'zeroone_trials': zeroone_trials,\n",
    "    'zerozero_trials': zerozero_trials\n",
    "}\n",
    "\n",
    "with open('noisy_channel_results.json', 'w') as f:\n",
    "    json.dump(results_data, f, indent=2)\n",
    "\n",
    "one_counts = Counter(one_trials)\n",
    "zero_counts = Counter(zero_trials)\n",
    "oneone_counts = Counter(oneone_trials)\n",
    "onezero_counts = Counter(onezero_trials)\n",
    "zeroone_counts = Counter(zeroone_trials)\n",
    "zerozero_counts = Counter(zerozero_trials)\n",
    "\n",
    "print(\"Mutation Summary:\")\n",
    "print(f\"Original '1' -> Mutations: {dict(one_counts)}\")\n",
    "print(f\"Original '0' -> Mutations: {dict(zero_counts)}\")\n",
    "print(f\"Original '11' -> Mutations: {dict(oneone_counts)}\")\n",
    "print(f\"Original '10' -> Mutations: {dict(onezero_counts)}\")\n",
    "print(f\"Original '01' -> Mutations: {dict(zeroone_counts)}\")\n",
    "print(f\"Original '00' -> Mutations: {dict(zerozero_counts)}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle(f'Noisy Channel Mutations ({num_trials} trials each)', fontsize=16)\n",
    "\n",
    "axes[0, 0].bar(one_counts.keys(), one_counts.values(), color='skyblue', alpha=0.7)\n",
    "axes[0, 0].set_title(\"Input: '1'\")\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[0, 1].bar(zero_counts.keys(), zero_counts.values(), color='lightcoral', alpha=0.7)\n",
    "axes[0, 1].set_title(\"Input: '0'\")\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[0, 2].bar(oneone_counts.keys(), oneone_counts.values(), color='lightgreen', alpha=0.7)\n",
    "axes[0, 2].set_title(\"Input: '11'\")\n",
    "axes[0, 2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[1, 0].bar(onezero_counts.keys(), onezero_counts.values(), color='gold', alpha=0.7)\n",
    "axes[1, 0].set_title(\"Input: '10'\")\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[1, 1].bar(zeroone_counts.keys(), zeroone_counts.values(), color='plum', alpha=0.7)\n",
    "axes[1, 1].set_title(\"Input: '01'\")\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[1, 2].bar(zerozero_counts.keys(), zerozero_counts.values(), color='orange', alpha=0.7)\n",
    "axes[1, 2].set_title(\"Input: '00'\")\n",
    "axes[1, 2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "all_outputs = set()\n",
    "all_outputs.update(one_counts.keys())\n",
    "all_outputs.update(zero_counts.keys())\n",
    "all_outputs.update(oneone_counts.keys())\n",
    "all_outputs.update(onezero_counts.keys())\n",
    "all_outputs.update(zeroone_counts.keys())\n",
    "all_outputs.update(zerozero_counts.keys())\n",
    "\n",
    "sorted_outputs = sorted(all_outputs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "x_pos = range(len(sorted_outputs))\n",
    "width = 0.13\n",
    "\n",
    "ax.bar([x - 2.5*width for x in x_pos], [one_counts.get(output, 0) for output in sorted_outputs],\n",
    "       width, label=\"Input: '1'\", alpha=0.8)\n",
    "ax.bar([x - 1.5*width for x in x_pos], [zero_counts.get(output, 0) for output in sorted_outputs],\n",
    "       width, label=\"Input: '0'\", alpha=0.8)\n",
    "ax.bar([x - 0.5*width for x in x_pos], [oneone_counts.get(output, 0) for output in sorted_outputs],\n",
    "       width, label=\"Input: '11'\", alpha=0.8)\n",
    "ax.bar([x + 0.5*width for x in x_pos], [onezero_counts.get(output, 0) for output in sorted_outputs],\n",
    "       width, label=\"Input: '10'\", alpha=0.8)\n",
    "ax.bar([x + 1.5*width for x in x_pos], [zeroone_counts.get(output, 0) for output in sorted_outputs],\n",
    "       width, label=\"Input: '01'\", alpha=0.8)\n",
    "ax.bar([x + 2.5*width for x in x_pos], [zerozero_counts.get(output, 0) for output in sorted_outputs],\n",
    "       width, label=\"Input: '00'\", alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Output Values')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title(f'Comparison of All Noisy Channel Outputs ({num_trials} trials each)')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(sorted_outputs)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nError Rates:\")\n",
    "print(f\"'1' -> correct: {one_counts.get('1', 0)/num_trials:.1%}, error: {(num_trials - one_counts.get('1', 0))/num_trials:.1%}\")\n",
    "print(f\"'0' -> correct: {zero_counts.get('0', 0)/num_trials:.1%}, error: {(num_trials - zero_counts.get('0', 0))/num_trials:.1%}\")\n",
    "print(f\"'11' -> correct: {oneone_counts.get('11', 0)/num_trials:.1%}, error: {(num_trials - oneone_counts.get('11', 0))/num_trials:.1%}\")\n",
    "print(f\"'10' -> correct: {onezero_counts.get('10', 0)/num_trials:.1%}, error: {(num_trials - onezero_counts.get('10', 0))/num_trials:.1%}\")\n",
    "print(f\"'01' -> correct: {zeroone_counts.get('01', 0)/num_trials:.1%}, error: {(num_trials - zeroone_counts.get('01', 0))/num_trials:.1%}\")\n",
    "print(f\"'00' -> correct: {zerozero_counts.get('00', 0)/num_trials:.1%}, error: {(num_trials - zerozero_counts.get('00', 0))/num_trials:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a binary tree to define our huffman encoding from the Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:57:58.172636Z",
     "start_time": "2025-08-28T20:57:57.951113Z"
    }
   },
   "outputs": [],
   "source": [
    "f = open('./corpus/brown-train-sentences.txt', 'r')\n",
    "corpus = f.read()\n",
    "\n",
    "chars: set[str] = set()\n",
    "char_freqs: dict[str, int] = {}\n",
    "\n",
    "for char in corpus:\n",
    "    if char in chars:\n",
    "        char_freqs[char] += 1\n",
    "    else:\n",
    "        chars.add(char)\n",
    "        char_freqs[char] = 1\n",
    "\n",
    "class BinaryTree:\n",
    "    def __init__(self, char: str, freq: int, left: 'BinaryTree' = None, right: 'BinaryTree' = None):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BinaryTree({self.char}, {self.freq}, {self.left}, {self.right})\"\n",
    "\n",
    "    def __lt__(self, other: 'BinaryTree') -> bool:\n",
    "        return self.freq < other.freq\n",
    "\n",
    "    def __le__(self, other: 'BinaryTree') -> bool:\n",
    "        return self.freq <= other.freq\n",
    "\n",
    "    def __gt__(self, other: 'BinaryTree') -> bool:\n",
    "        return self.freq > other.freq\n",
    "\n",
    "    def __ge__(self, other: 'BinaryTree') -> bool:\n",
    "        return self.freq >= other.freq\n",
    "\n",
    "    def __eq__(self, other: 'BinaryTree') -> bool:\n",
    "        return self.freq == other.freq\n",
    "\n",
    "binary_trees: list[BinaryTree] = []\n",
    "# Could add punctuation, but you don't really need it for sending an intelligible message\n",
    "alphabet: set[str] = {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' '}\n",
    "for char, freq in char_freqs.items():\n",
    "    if char in alphabet:\n",
    "        binary_trees.append(BinaryTree(char, freq))\n",
    "\n",
    "binary_trees = sorted(binary_trees, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary for fast encoding and decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:58:00.012616Z",
     "start_time": "2025-08-28T20:58:00.008877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0000': 'h', '00010': 'u', '00011': 'c', '001': 'e', '0100': 'r', '0101': 's', '0110': 'n', '011100': 'b', '011101': 'y', '011110': 'w', '011111': 'g', '1000': 'i', '1001': 'o', '1010': 'a', '10110': 'd', '10111': 'l', '110000': 'p', '1100010': 'v', '1100011000': 'z', '1100011001': 'q', '1100011010': 'j', '1100011011': 'x', '11000111': 'k', '110010': 'f', '110011': 'm', '1101': 't', '111': ' '}\n"
     ]
    }
   ],
   "source": [
    "while len(binary_trees) > 1:\n",
    "    last_tree: BinaryTree = binary_trees.pop()\n",
    "    second_last_tree: BinaryTree = binary_trees.pop()\n",
    "    # /nac is reserved\n",
    "    new_tree = BinaryTree(\"/nac\", last_tree.freq + second_last_tree.freq, last_tree, second_last_tree)\n",
    "    binary_trees.append(new_tree)\n",
    "    binary_trees = sorted(binary_trees, reverse=True)\n",
    "\n",
    "huffman_encoding: dict[str, str] = {}\n",
    "huffman_decoding: dict[str, str] = {}\n",
    "def find_paths(tree: BinaryTree, path: str = \"\") -> None:\n",
    "    if tree.left is None and tree.right is None:\n",
    "        huffman_encoding[tree.char] = path\n",
    "        huffman_decoding[path] = tree.char\n",
    "    else:\n",
    "        find_paths(tree.left, path + \"0\")\n",
    "        find_paths(tree.right, path + \"1\")\n",
    "\n",
    "find_paths(binary_trees[0])\n",
    "print(huffman_decoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test encoding and decoding a message with our Huffman encode/decode function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:58:01.310723Z",
     "start_time": "2025-08-28T20:58:01.307035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000110111101111001111011110100101001011110110\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "message = \"hello world\"\n",
    "\n",
    "def encode(message: str, huffman_encoding: dict[str, str]) -> str:\n",
    "    encoded_message = \"\"\n",
    "    for char in message:\n",
    "        encoded_message += huffman_encoding[char]\n",
    "    return encoded_message\n",
    "\n",
    "def decode(message: str, huffman_decoding: dict[str, str]) -> str:\n",
    "    decoded_message = \"\"\n",
    "    temp_code = \"\"\n",
    "    for char in message:\n",
    "        temp_code += char\n",
    "        if temp_code in huffman_decoding.keys():\n",
    "            decoded_message += huffman_decoding[temp_code]\n",
    "            temp_code = \"\"\n",
    "    return decoded_message\n",
    "\n",
    "encoded_message: str = encode(message, huffman_encoding)\n",
    "print(encoded_message)\n",
    "decoded_message: str = decode(encoded_message, huffman_decoding)\n",
    "print(decoded_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add hamming code to our huffman encoded message, so we know when a bit was flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:58:02.643063Z",
     "start_time": "2025-08-28T20:58:02.633485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000110111101111001111011110100101001011110110\n",
      "100111011111010001010010111101101100111101111011000000\n",
      "100111011111010001010010111101101100111101111011000001\n",
      "000000110111101111001111011110100101001011110110\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def add_hamming_code(data_bits: str) -> str:\n",
    "    parity_bits = 0\n",
    "    # Would be worth memoizing\n",
    "    while 2 ** parity_bits < (len(data_bits) + parity_bits + 1):\n",
    "        parity_bits += 1\n",
    "\n",
    "    hamming_coded_array: list[str] = []\n",
    "    data_iterator = iter(reversed(data_bits))\n",
    "    parities: list[str] = []\n",
    "\n",
    "    # We're following https://en.wikipedia.org/wiki/Hamming_code#General_algorithm\n",
    "    # theta(k)\n",
    "    for i in range(1, len(data_bits) + parity_bits + 1):\n",
    "        if i & (i - 1) == 0:\n",
    "            hamming_coded_array.append('x')\n",
    "        else:\n",
    "            hamming_coded_array.append(next(data_iterator))\n",
    "\n",
    "    # Garbage theta(n*k) code, but it works for now\n",
    "    for i in range(parity_bits):\n",
    "        parity = 'x'\n",
    "        for j, bit in enumerate(hamming_coded_array):\n",
    "            if (j + 1) & (1 << i) != 0 and bit != 'x':\n",
    "                if parity == 'x' :\n",
    "                    parity = int(bit)\n",
    "                else:\n",
    "                    parity = int(bit) ^ parity\n",
    "        parities.append(str(parity))\n",
    "\n",
    "    # theta(n)\n",
    "    for i, bit in enumerate(hamming_coded_array):\n",
    "        if bit == 'x':\n",
    "            hamming_coded_array[i] = parities.pop(0)\n",
    "\n",
    "    return \"\".join(hamming_coded_array)\n",
    "\n",
    "def remove_hamming_code(hamming_bits: str) -> str:\n",
    "    parity_bits = math.floor(math.log(len(hamming_bits), 2)) + 1\n",
    "\n",
    "    expected_parities: list[int] = []\n",
    "    parities: list[int] = [-1] * parity_bits\n",
    "    data_bits: list[str] = []\n",
    "    is_error: bool = False\n",
    "    error_idx: int = 0\n",
    "\n",
    "    for i in range(1, len(hamming_bits) + 1):\n",
    "        if i & (i - 1) == 0:\n",
    "            expected_parities.append(int(hamming_bits[i - 1]))\n",
    "        else:\n",
    "            data_bits.append(hamming_bits[i - 1])\n",
    "            for j in range(parity_bits):\n",
    "                if i & (1 << j) != 0:\n",
    "                    if parities[j] == -1:\n",
    "                        parities[j] = int(hamming_bits[i - 1])\n",
    "                    else:\n",
    "                        parities[j] = int(hamming_bits[i - 1]) ^ parities[j]\n",
    "\n",
    "    for i in range(parity_bits):\n",
    "        if expected_parities[i] != parities[i]:\n",
    "            is_error = True\n",
    "            error_idx += 2 ** i\n",
    "\n",
    "    if is_error:\n",
    "        original_message = list(hamming_bits)\n",
    "        original_message[error_idx - 1] = str(int(original_message[error_idx - 1]) ^ 1)\n",
    "        data_bits = []\n",
    "        for i in range(1, len(hamming_bits) + 1):\n",
    "            if i & (i - 1) != 0:\n",
    "                data_bits.append(original_message[i - 1])\n",
    "\n",
    "    return \"\".join(data_bits.__reversed__())\n",
    "\n",
    "print(encoded_message)\n",
    "hamming_coded_message = add_hamming_code(encoded_message)\n",
    "print(hamming_coded_message)\n",
    "hamming_coded_message_corrupted = str(int(hamming_coded_message) + 1)\n",
    "print(hamming_coded_message_corrupted)\n",
    "hamming_decoded_message = remove_hamming_code(hamming_coded_message_corrupted)\n",
    "print(hamming_decoded_message)\n",
    "print(decode(hamming_decoded_message, huffman_decoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our own homemade Noisy Channel Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Iterable, List, Tuple, Union, Optional\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    _HAS_NUMPY = True\n",
    "except Exception:\n",
    "    _HAS_NUMPY = False\n",
    "\n",
    "BitsIn  = Union[str, Iterable[int]]\n",
    "BitsOut = Union[str, List[int]]\n",
    "\n",
    "\n",
    "def our_noisy_channel(\n",
    "    bits: BitsIn,\n",
    "    p_flip: Optional[float] = None,\n",
    "    threshold: Optional[float] = None,\n",
    "    seed: Optional[int] = None,\n",
    "    return_indices: bool = False,\n",
    ") -> Union[Tuple[BitsOut, int], Tuple[BitsOut, int, List[int]]]:\n",
    "\n",
    "\n",
    "    # --- validate parameters ---\n",
    "    if p_flip is None and threshold is None:\n",
    "        raise ValueError(\"Provide either p_flip or threshold.\")\n",
    "    if p_flip is not None:\n",
    "        if not (0.0 <= p_flip <= 1.0):\n",
    "            raise ValueError(\"p_flip must be in [0,1].\")\n",
    "    if threshold is not None:\n",
    "        if not (0.0 <= threshold <= 1.0):\n",
    "            raise ValueError(\"threshold must be in [0,1].\")\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    # --- normalize input to a list of ints ---\n",
    "    input_is_str = isinstance(bits, str)\n",
    "    if input_is_str:\n",
    "        if any(ch not in \"01\" for ch in bits):\n",
    "            raise ValueError(\"String inputs must contain only '0' and '1'.\")\n",
    "        bit_list = [int(ch) for ch in bits]\n",
    "    else:\n",
    "        # Accept any iterable of ints/bools\n",
    "        try:\n",
    "            bit_list = [int(b) for b in bits]\n",
    "        except TypeError:\n",
    "            raise TypeError(\"`bits` must be a string '01...' or an iterable of 0/1.\")\n",
    "        if any(b not in (0, 1) for b in bit_list):\n",
    "            raise ValueError(\"All elements in `bits` must be 0 or 1.\")\n",
    "\n",
    "    n = len(bit_list)\n",
    "    flipped_indices: List[int] = []\n",
    "\n",
    "    # --- flip rule ---\n",
    "    # If p_flip is given: flip when u < p_flip.\n",
    "    # If threshold is given: flip when u > threshold (as per your description).\n",
    "    use_p = p_flip is not None\n",
    "    p = p_flip if use_p else (1.0 - threshold)  # effective flip probability (for reference)\n",
    "\n",
    "    for i in range(n):\n",
    "        u = rng.random()  # U(0,1)\n",
    "        do_flip = (u < p_flip) if use_p else (u > threshold)\n",
    "        if do_flip:\n",
    "            bit_list[i] ^= 1  # flip 0<->1\n",
    "            flipped_indices.append(i)\n",
    "\n",
    "    # --- pack output in same type as input ---\n",
    "    flipped_bits: BitsOut = \"\".join(str(b) for b in bit_list) if input_is_str else bit_list\n",
    "    n_flipped = len(flipped_indices)\n",
    "\n",
    "    if return_indices:\n",
    "        return flipped_bits, n_flipped, flipped_indices\n",
    "    return flipped_bits, n_flipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first test our hamming error correct in our hommade noisy channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a super duper long message'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def send_message(message: str, packet_size: tuple[int, int] = (7, 4)) -> str:\n",
    "    huffman_encoded_message = encode(message, huffman_encoding)\n",
    "    whole_huffman_decoded_message = \"\"\n",
    "    # Should parallelize this, but I don't want to DDoS Bijan\n",
    "    for packet in range(0, len(huffman_encoded_message), packet_size[1]):\n",
    "        curr_packet = huffman_encoded_message[packet:packet + packet_size[1]]\n",
    "        hamming_encoded_packet = add_hamming_code(curr_packet)\n",
    "        noisy_packet = our_noisy_channel(hamming_encoded_packet, p_flip=0.03)[0]\n",
    "        # noisy_packet = noisy_channel(hamming_encoded_packet) --- IGNORE ---\n",
    "        whole_huffman_decoded_message += remove_hamming_code(noisy_packet)\n",
    "    return decode(whole_huffman_decoded_message, huffman_decoding)\n",
    "\n",
    "send_message(\"a super duper long message\") #message length is 110 bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated the error for the below 110-bit message when run through our noisy channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over 50 Trials: 76.0%\n"
     ]
    }
   ],
   "source": [
    "message_trials = 50\n",
    "correct = 0\n",
    "\n",
    "for i in range(message_trials):\n",
    "    message = \"a super duper long message\"\n",
    "    if send_message(message) == message:\n",
    "        correct += 1\n",
    "\n",
    "print(\"Accuracy over 50 Trials:\", str(round(100*(float(correct) / float(message_trials)), 2))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the message through the actual web-hosted noisy channel, note that you get different outputs based off of the channel's \"mood\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:58:27.046169Z",
     "start_time": "2025-08-28T20:58:14.167481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a super dupertwso   eossage'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def send_message(message: str, packet_size: tuple[int, int] = (7, 4)) -> str:\n",
    "    huffman_encoded_message = encode(message, huffman_encoding)\n",
    "    whole_huffman_decoded_message = \"\"\n",
    "    # Should parallelize this, but I don't want to DDoS Bijan\n",
    "    for packet in range(0, len(huffman_encoded_message), packet_size[1]):\n",
    "        curr_packet = huffman_encoded_message[packet:packet + packet_size[1]]\n",
    "        hamming_encoded_packet = add_hamming_code(curr_packet)\n",
    "        noisy_packet = noisy_channel(hamming_encoded_packet)\n",
    "        whole_huffman_decoded_message += remove_hamming_code(noisy_packet)\n",
    "    return decode(whole_huffman_decoded_message, huffman_decoding)\n",
    "\n",
    "send_message(\"a super duper long message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated the error for the below 110-bit message in the web-hosted channel at about 86.67% accuracy, but this can vary, based on the channel's \"mood\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T23:06:15.560902Z",
     "start_time": "2025-08-28T23:06:15.482912Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'send_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(message_trials):\n\u001b[32m      5\u001b[39m     message = \u001b[33m\"\u001b[39m\u001b[33ma super duper long message\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msend_message\u001b[49m(message) == message:\n\u001b[32m      7\u001b[39m         correct += \u001b[32m1\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(correct) / \u001b[38;5;28mfloat\u001b[39m(message_trials))\n",
      "\u001b[31mNameError\u001b[39m: name 'send_message' is not defined"
     ]
    }
   ],
   "source": [
    "message_trials = 50\n",
    "correct = 0\n",
    "\n",
    "for i in range(message_trials):\n",
    "    message = \"a super duper long message\"\n",
    "    if send_message(message) == message:\n",
    "        correct += 1\n",
    "\n",
    "print(float(correct) / float(message_trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDPC (Low-Density Parity-Check) coding over the noisy channel\n",
    "We implement a simple systematic LDPC scheme with H = [A | I], allowing configurable block length n (data k + parity m), a min-sum BP decoder, and an end-to-end `send_message_ldpc` that operates on Huffman-encoded bits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from typing import Tuple, List\n",
    "\n",
    "# ------------------------------\n",
    "# LDPC matrix construction (simple, reproducible)\n",
    "# ------------------------------\n",
    "\n",
    "def build_ldpc_h(k: int, m: int, col_weight: int = 3, seed: int = 42) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Build a simple parity-check matrix H of size m x (k+m) in systematic form [A | I_m].\n",
    "    A is m x k, each column has 'col_weight' ones placed at random rows.\n",
    "    This is not capacity-optimized but works for demonstration/testing.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    A = [[0 for _ in range(k)] for _ in range(m)]\n",
    "    for col in range(k):\n",
    "        rows = random.sample(range(m), min(col_weight, m))\n",
    "        for r in rows:\n",
    "            A[r][col] = 1\n",
    "    # Identity part\n",
    "    H = [row[:] + [1 if i == r else 0 for i in range(m)] for r, row in enumerate(A)]\n",
    "    return H\n",
    "\n",
    "# ------------------------------\n",
    "# Systematic encoding: x = [d | p] s.t. H x^T = 0 over GF(2)\n",
    "# Since H = [A|I], parity p = A * d (mod 2)\n",
    "# ------------------------------\n",
    "\n",
    "def ldpc_encode_block(data_bits: List[int], H: List[List[int]]) -> List[int]:\n",
    "    m = len(H)\n",
    "    k = len(H[0]) - m\n",
    "    # Extract A (m x k)\n",
    "    A = [row[:k] for row in H]\n",
    "    # p = A * d (mod 2)\n",
    "    p = []\n",
    "    for r in range(m):\n",
    "        s = 0\n",
    "        for c in range(k):\n",
    "            s ^= (A[r][c] & data_bits[c])\n",
    "        p.append(s)\n",
    "    return data_bits + p\n",
    "\n",
    "# ------------------------------\n",
    "# Min-sum belief propagation LDPC decoder\n",
    "# ------------------------------\n",
    "\n",
    "def ldpc_decode_block_min_sum(received_bits: List[int], H: List[List[int]], p_error: float = 0.02,\n",
    "                               max_iters: int = 50) -> Tuple[List[int], bool]:\n",
    "    \"\"\"\n",
    "    Min-sum decoder on BSC(p_error). Returns (decoded_bits, success_flag).\n",
    "    Assumes systematic [d|p].\n",
    "    \"\"\"\n",
    "    m = len(H)\n",
    "    n = len(H[0])\n",
    "    # Build factor graph adjacency\n",
    "    checks = [[] for _ in range(m)]\n",
    "    vars_neighbors = [[] for _ in range(n)]\n",
    "    for r in range(m):\n",
    "        for c in range(n):\n",
    "            if H[r][c] == 1:\n",
    "                checks[r].append(c)\n",
    "                vars_neighbors[c].append(r)\n",
    "\n",
    "    # Channel LLRs for BSC: LLR = log((1-p)/p) * (1-2*y)\n",
    "    tiny = 1e-12\n",
    "    Lc = math.log(max((1 - p_error) / max(p_error, tiny), tiny))\n",
    "    Lch = [Lc * (1 - 2 * y) for y in received_bits]\n",
    "\n",
    "    # Messages: r_{c->v} and q_{v->c}\n",
    "    r = { (c,v): 0.0 for c in range(m) for v in checks[c] }\n",
    "    q = { (v,c): Lch[v] for v in range(n) for c in vars_neighbors[v] }\n",
    "\n",
    "    def hard_decision(llrs: List[float]) -> List[int]:\n",
    "        return [0 if L >= 0 else 1 for L in llrs]\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        # Check node update (min-sum)\n",
    "        for c in range(m):\n",
    "            neigh = checks[c]\n",
    "            # For each v in neigh, compute sign and minimum excluding v\n",
    "            signs = [1 if q[(v,c)] >= 0 else -1 for v in neigh]\n",
    "            abs_vals = [abs(q[(v,c)]) for v in neigh]\n",
    "            total_sign = 1\n",
    "            for s in signs:\n",
    "                total_sign *= s\n",
    "            min1 = float('inf'); min2 = float('inf'); idx_min = -1\n",
    "            for i, a in enumerate(abs_vals):\n",
    "                if a < min1:\n",
    "                    min2 = min1\n",
    "                    min1 = a\n",
    "                    idx_min = i\n",
    "                elif a < min2:\n",
    "                    min2 = a\n",
    "            for i, v in enumerate(neigh):\n",
    "                sign_i = total_sign * (1 if q[(v,c)] >= 0 else -1)\n",
    "                mag = min2 if i == idx_min else min1\n",
    "                r[(c,v)] = sign_i * mag\n",
    "\n",
    "        # Variable node update\n",
    "        posterior = [Lch[v] for v in range(n)]\n",
    "        for v in range(n):\n",
    "            for c in vars_neighbors[v]:\n",
    "                posterior[v] += r[(c,v)]\n",
    "        # Early stop check\n",
    "        x_hat = hard_decision(posterior)\n",
    "        # Syndrome check H x^T == 0\n",
    "        ok = True\n",
    "        for c in range(m):\n",
    "            s = 0\n",
    "            for v in checks[c]:\n",
    "                s ^= x_hat[v]\n",
    "            if s != 0:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            return x_hat, True\n",
    "        # Update q\n",
    "        for v in range(n):\n",
    "            for c in vars_neighbors[v]:\n",
    "                q[(v,c)] = posterior[v] - r[(c,v)]\n",
    "\n",
    "    # Final hard decision\n",
    "    x_hat = hard_decision([Lch[v] + sum(r[(c,v)] for c in vars_neighbors[v]) for v in range(n)])\n",
    "    ok = True\n",
    "    for c in range(m):\n",
    "        s = 0\n",
    "        for v in checks[c]:\n",
    "            s ^= x_hat[v]\n",
    "        if s != 0:\n",
    "            ok = False\n",
    "            break\n",
    "    return x_hat, ok\n",
    "\n",
    "# ------------------------------\n",
    "# Framing and end-to-end helpers\n",
    "# ------------------------------\n",
    "\n",
    "def bits_from_str(bit_str: str) -> List[int]:\n",
    "    return [1 if b == '1' else 0 for b in bit_str]\n",
    "\n",
    "def str_from_bits(bits: List[int]) -> str:\n",
    "    return ''.join('1' if b else '0' for b in bits)\n",
    "\n",
    "\n",
    "def pad_bits(bits: List[int], block_k: int) -> Tuple[List[int], int]:\n",
    "    \"\"\"Pad with zeros so len is multiple of block_k. Return (padded, pad_len).\"\"\"\n",
    "    r = len(bits) % block_k\n",
    "    pad = (block_k - r) if r != 0 else 0\n",
    "    return bits + [0]*pad, pad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will now put everything together in order to send messages through our homemade channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_ldpc_our_channel(message: str, p: float,\n",
    "                       n: int = 1000,\n",
    "                       k: int = 110,\n",
    "                       col_weight: int = 3,\n",
    "                       p_bsc: float = 0.02,\n",
    "                       max_iters: int = 50,\n",
    "                       seed: int = 42) -> str:\n",
    "    \"\"\"\n",
    "    End-to-end: Huffman-encode -> chunk k bits -> LDPC encode to n -> transmit via noisy_channel ->\n",
    "    LDPC decode -> remove pad -> Huffman-decode.\n",
    "\n",
    "    - n: total block length (data k + parity m)\n",
    "    - k: number of data bits per block\n",
    "    \"\"\"\n",
    "    assert n > k > 0, \"n must be > k > 0\"\n",
    "    m = n - k\n",
    "    H = build_ldpc_h(k, m, col_weight=col_weight, seed=seed)\n",
    "\n",
    "    # Huffman encode\n",
    "    bit_str = encode(message, huffman_encoding)\n",
    "    bits = bits_from_str(bit_str)\n",
    "\n",
    "    # Pad to multiple of k\n",
    "    bits_padded, pad_len = pad_bits(bits, k)\n",
    "\n",
    "    decoded_bits_total: List[int] = []\n",
    "    \n",
    "    # Process each k-bit chunk\n",
    "    for i in range(0, len(bits_padded), k):\n",
    "        d = bits_padded[i:i+k]\n",
    "        x = ldpc_encode_block(d, H)  # length n\n",
    "        # Send via noisy channel as string\n",
    "        tx = str_from_bits(x)\n",
    "        rx = our_noisy_channel(tx, p)[0]\n",
    "        y = bits_from_str(rx)\n",
    "        # Decode\n",
    "        x_hat, ok = ldpc_decode_block_min_sum(y, H, p_error=p_bsc, max_iters=max_iters)\n",
    "        d_hat = x_hat[:k]\n",
    "        decoded_bits_total.extend(d_hat)\n",
    "\n",
    "    # Remove padding\n",
    "    if pad_len:\n",
    "        decoded_bits_total = decoded_bits_total[:-pad_len]\n",
    "\n",
    "    # Huffman decode\n",
    "    decoded_bit_str = str_from_bits(decoded_bits_total)\n",
    "    return decode(decoded_bit_str, huffman_decoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this function sends the messages through the web-hosted channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_ldpc(message: str,\n",
    "                       n: int = 1000,\n",
    "                       k: int = 110,\n",
    "                       col_weight: int = 3,\n",
    "                       p_bsc: float = 0.02,\n",
    "                       max_iters: int = 50,\n",
    "                       seed: int = 42) -> str:\n",
    "    \"\"\"\n",
    "    End-to-end: Huffman-encode -> chunk k bits -> LDPC encode to n -> transmit via noisy_channel ->\n",
    "    LDPC decode -> remove pad -> Huffman-decode.\n",
    "\n",
    "    - n: total block length (data k + parity m)\n",
    "    - k: number of data bits per block\n",
    "    \"\"\"\n",
    "    assert n > k > 0, \"n must be > k > 0\"\n",
    "    m = n - k\n",
    "    H = build_ldpc_h(k, m, col_weight=col_weight, seed=seed)\n",
    "\n",
    "    # Huffman encode\n",
    "    bit_str = encode(message, huffman_encoding)\n",
    "    bits = bits_from_str(bit_str)\n",
    "\n",
    "    # Pad to multiple of k\n",
    "    bits_padded, pad_len = pad_bits(bits, k)\n",
    "\n",
    "    decoded_bits_total: List[int] = []\n",
    "    \n",
    "    # Process each k-bit chunk\n",
    "    for i in range(0, len(bits_padded), k):\n",
    "        d = bits_padded[i:i+k]\n",
    "        x = ldpc_encode_block(d, H)  # length n\n",
    "        # Send via noisy channel as string\n",
    "        tx = str_from_bits(x)\n",
    "        rx = noisy_channel(tx)\n",
    "        y = bits_from_str(rx)\n",
    "        # Decode\n",
    "        x_hat, ok = ldpc_decode_block_min_sum(y, H, p_error=p_bsc, max_iters=max_iters)\n",
    "        d_hat = x_hat[:k]\n",
    "        decoded_bits_total.extend(d_hat)\n",
    "\n",
    "    # Remove padding\n",
    "    if pad_len:\n",
    "        decoded_bits_total = decoded_bits_total[:-pad_len]\n",
    "\n",
    "    # Huffman decode\n",
    "    decoded_bit_str = str_from_bits(decoded_bits_total)\n",
    "    return decode(decoded_bit_str, huffman_decoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the functions to send a message through our homemade channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: a super duper long message\n",
      "Accuracy over 50 trials: 68.00%\n",
      "Decoded: a super duper long message\n"
     ]
    }
   ],
   "source": [
    "# Example usage: configure (n, k), column weight, and BSC p for the decoder\n",
    "# Typical small demo: (n=1000, k=110) gives rate ~0.70\n",
    "\n",
    "msg = \"a super duper long message\"\n",
    "print(\"Original:\", msg)\n",
    "\n",
    "# Try a few trials to gauge robustness\n",
    "trials = 50\n",
    "ok = 0\n",
    "for _ in range(trials):\n",
    "    out = send_message_ldpc_our_channel(msg, p=0.03, n=1000, k=110, col_weight=3, p_bsc=0.02, max_iters=50, seed=123)\n",
    "    if out == msg:\n",
    "        ok += 1\n",
    "print(f\"Accuracy over {trials} trials: {ok/trials:.2%}\")\n",
    "\n",
    "# Single run print\n",
    "decoded = send_message_ldpc_our_channel(msg, p=0.03, n=1000, k=110, col_weight=3, p_bsc=0.02, max_iters=50, seed=123)\n",
    "print(\"Decoded:\", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the functions to send a message through the web-hosted channel, which sometimes returns clear messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: a super duper long message\n",
      "Accuracy over 50 trials: 86.00%\n",
      "Decoded: a super duper long message\n"
     ]
    }
   ],
   "source": [
    "# Example usage: configure (n, k), column weight, and BSC p for the decoder\n",
    "# Typical small demo: (n=1000, k=110) gives rate ~0.70\n",
    "\n",
    "msg = \"a super duper long message\"\n",
    "print(\"Original:\", msg)\n",
    "\n",
    "# Try a few trials to gauge robustness\n",
    "trials = 50\n",
    "ok = 0\n",
    "for _ in range(trials):\n",
    "    out = send_message_ldpc(msg, n=1000, k=110, col_weight=3, p_bsc=0.02, max_iters=50, seed=123)\n",
    "    if out == msg:\n",
    "        ok += 1\n",
    "print(f\"Accuracy over {trials} trials: {ok/trials:.2%}\")\n",
    "\n",
    "# Single run print\n",
    "decoded = send_message_ldpc(msg, n=1000, k=110, col_weight=3, p_bsc=0.02, max_iters=50, seed=123)\n",
    "print(\"Decoded:\", decoded)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
